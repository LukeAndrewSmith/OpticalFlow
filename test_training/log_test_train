Sender: LSF System <lsfadmin@lo-s4-034>
Subject: Job 16032241: <python main.py /cluster/project/infk/hilliges/lectures/mp21/project6/dataset/ --dataset humanflow --pretrained /cluster/home/lusmith/BananaPyjama/pretrained/pwc_MHOF.pth.tar> in cluster <leonhard> Exited

Job <python main.py /cluster/project/infk/hilliges/lectures/mp21/project6/dataset/ --dataset humanflow --pretrained /cluster/home/lusmith/BananaPyjama/pretrained/pwc_MHOF.pth.tar> was submitted from host <lo-login-01> by user <lusmith> in cluster <leonhard> at Mon May  3 11:43:56 2021
Job was executed on host(s) <lo-s4-034>, in queue <gpu.4h>, as user <lusmith> in cluster <leonhard> at Mon May  3 11:44:17 2021
</cluster/home/lusmith> was used as the home directory.
</cluster/home/lusmith/BananaPyjama> was used as the working directory.
Started at Mon May  3 11:44:17 2021
Terminated at Mon May  3 12:44:01 2021
Results reported at Mon May  3 12:44:01 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py /cluster/project/infk/hilliges/lectures/mp21/project6/dataset/ --dataset humanflow --pretrained /cluster/home/lusmith/BananaPyjama/pretrained/pwc_MHOF.pth.tar
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   7138.00 sec.
    Max Memory :                                 4096 MB
    Average Memory :                             3964.47 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              11
    Max Threads :                                47
    Run time :                                   3606 sec.
    Turnaround time :                            3605 sec.

The output (if any) follows:

=> will save everything to checkpoints/demo
=> fetching img pairs in '/cluster/project/infk/hilliges/lectures/mp21/project6/dataset/'
8343 samples found, 8343 train samples and 0 test samples 
=> using pre-trained model 'pwc'
=> setting adam solver
/cluster/home/lusmith/BananaPyjama/models/PWCNet.py:146: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  nn.init.kaiming_normal(m.weight.data, mode='fan_in')
/cluster/apps/python/3.8.5_gpu_gcc630/x86_64/lib64/python3.8/site-packages/torch/optim/lr_scheduler.py:118: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Epoch: [0][0/1000]	 Time 30.290 (30.290)	 Data 25.317 (25.317)	 Loss 17.902 (17.902)	 EPE 1.722 (1.722)
Epoch: [0][10/1000]	 Time 0.667 (5.016)	 Data 0.000 (3.953)	 Loss 13.408 (15.411)	 EPE 1.037 (1.213)
Epoch: [0][20/1000]	 Time 0.734 (3.906)	 Data 0.000 (3.015)	 Loss 11.736 (14.030)	 EPE 0.841 (1.084)
Epoch: [0][30/1000]	 Time 0.635 (3.540)	 Data 0.005 (2.729)	 Loss 11.768 (13.510)	 EPE 0.718 (1.030)
Epoch: [0][40/1000]	 Time 18.011 (3.778)	 Data 17.315 (3.006)	 Loss 13.447 (13.125)	 EPE 0.936 (0.997)
Epoch: [0][50/1000]	 Time 4.188 (3.667)	 Data 3.498 (2.914)	 Loss 11.515 (12.851)	 EPE 0.784 (0.969)
Epoch: [0][60/1000]	 Time 0.678 (3.533)	 Data 0.010 (2.793)	 Loss 10.962 (12.551)	 EPE 0.762 (0.931)
Epoch: [0][70/1000]	 Time 0.678 (3.430)	 Data 0.000 (2.699)	 Loss 10.922 (12.414)	 EPE 0.684 (0.919)
Epoch: [0][80/1000]	 Time 12.928 (3.502)	 Data 12.280 (2.779)	 Loss 12.072 (12.224)	 EPE 1.133 (0.899)
Epoch: [0][90/1000]	 Time 9.651 (3.520)	 Data 9.010 (2.806)	 Loss 10.292 (12.050)	 EPE 0.705 (0.874)
Epoch: [0][100/1000]	 Time 0.634 (3.440)	 Data 0.005 (2.731)	 Loss 11.566 (11.941)	 EPE 0.819 (0.857)
Epoch: [0][110/1000]	 Time 0.721 (3.388)	 Data 0.000 (2.681)	 Loss 10.998 (11.858)	 EPE 0.638 (0.848)
Epoch: [0][120/1000]	 Time 9.278 (3.417)	 Data 8.634 (2.714)	 Loss 9.421 (11.788)	 EPE 0.708 (0.842)
Epoch: [0][130/1000]	 Time 13.163 (3.463)	 Data 12.506 (2.762)	 Loss 9.390 (11.649)	 EPE 0.581 (0.826)
Epoch: [0][140/1000]	 Time 0.674 (3.414)	 Data 0.011 (2.716)	 Loss 9.838 (11.531)	 EPE 0.551 (0.811)
Epoch: [0][150/1000]	 Time 0.704 (3.376)	 Data 0.000 (2.681)	 Loss 9.417 (11.458)	 EPE 0.550 (0.800)
Epoch: [0][160/1000]	 Time 5.189 (3.369)	 Data 4.516 (2.677)	 Loss 11.578 (11.378)	 EPE 0.778 (0.793)
Epoch: [0][170/1000]	 Time 15.961 (3.435)	 Data 15.322 (2.744)	 Loss 10.742 (11.333)	 EPE 0.733 (0.788)
Epoch: [0][180/1000]	 Time 0.670 (3.399)	 Data 0.005 (2.711)	 Loss 10.622 (11.284)	 EPE 0.790 (0.783)
Epoch: [0][190/1000]	 Time 0.668 (3.366)	 Data 0.000 (2.679)	 Loss 10.663 (11.241)	 EPE 0.619 (0.777)
Epoch: [0][200/1000]	 Time 1.013 (3.336)	 Data 0.396 (2.650)	 Loss 10.219 (11.205)	 EPE 0.479 (0.769)
Epoch: [0][210/1000]	 Time 16.409 (3.404)	 Data 15.740 (2.719)	 Loss 11.653 (11.233)	 EPE 0.585 (0.773)
Epoch: [0][220/1000]	 Time 0.711 (3.377)	 Data 0.020 (2.692)	 Loss 11.237 (11.218)	 EPE 0.759 (0.776)
Epoch: [0][230/1000]	 Time 0.866 (3.348)	 Data 0.020 (2.664)	 Loss 10.136 (11.206)	 EPE 0.657 (0.772)
Epoch: [0][240/1000]	 Time 0.639 (3.325)	 Data 0.000 (2.641)	 Loss 15.843 (11.191)	 EPE 1.349 (0.772)
Epoch: [0][250/1000]	 Time 19.454 (3.383)	 Data 18.726 (2.699)	 Loss 10.503 (11.202)	 EPE 0.635 (0.773)
Epoch: [0][260/1000]	 Time 0.677 (3.357)	 Data 0.000 (2.675)	 Loss 9.995 (11.168)	 EPE 0.606 (0.767)
Epoch: [0][270/1000]	 Time 0.716 (3.334)	 Data 0.000 (2.651)	 Loss 10.391 (11.139)	 EPE 0.765 (0.762)
Epoch: [0][280/1000]	 Time 0.686 (3.313)	 Data 0.000 (2.630)	 Loss 10.043 (11.104)	 EPE 0.602 (0.757)
Epoch: [0][290/1000]	 Time 20.690 (3.362)	 Data 20.039 (2.680)	 Loss 10.157 (11.068)	 EPE 0.622 (0.753)
Epoch: [0][300/1000]	 Time 0.681 (3.343)	 Data 0.000 (2.661)	 Loss 7.582 (11.045)	 EPE 0.387 (0.747)
Epoch: [0][310/1000]	 Time 0.705 (3.329)	 Data 0.005 (2.647)	 Loss 11.119 (11.025)	 EPE 0.886 (0.745)
Epoch: [0][320/1000]	 Time 0.695 (3.313)	 Data 0.000 (2.631)	 Loss 9.186 (10.996)	 EPE 0.617 (0.743)
Epoch: [0][330/1000]	 Time 22.815 (3.367)	 Data 21.983 (2.684)	 Loss 10.295 (10.960)	 EPE 0.443 (0.737)
Epoch: [0][340/1000]	 Time 0.625 (3.350)	 Data 0.010 (2.666)	 Loss 9.778 (10.946)	 EPE 0.438 (0.731)
Epoch: [0][350/1000]	 Time 0.755 (3.335)	 Data 0.016 (2.650)	 Loss 10.127 (10.923)	 EPE 0.777 (0.729)
Epoch: [0][360/1000]	 Time 0.721 (3.320)	 Data 0.005 (2.636)	 Loss 7.739 (10.884)	 EPE 0.505 (0.724)
Epoch: [0][370/1000]	 Time 21.992 (3.365)	 Data 21.321 (2.681)	 Loss 11.138 (10.865)	 EPE 0.547 (0.719)
Epoch: [0][380/1000]	 Time 0.726 (3.352)	 Data 0.000 (2.667)	 Loss 9.319 (10.852)	 EPE 0.642 (0.717)
Epoch: [0][390/1000]	 Time 0.694 (3.339)	 Data 0.015 (2.654)	 Loss 7.986 (10.830)	 EPE 0.638 (0.714)
Epoch: [0][400/1000]	 Time 0.726 (3.330)	 Data 0.000 (2.645)	 Loss 8.019 (10.807)	 EPE 0.503 (0.711)
Epoch: [0][410/1000]	 Time 21.797 (3.369)	 Data 21.021 (2.684)	 Loss 13.076 (10.804)	 EPE 1.204 (0.711)
Epoch: [0][420/1000]	 Time 0.716 (3.356)	 Data 0.007 (2.671)	 Loss 10.805 (10.796)	 EPE 0.579 (0.710)
Epoch: [0][430/1000]	 Time 0.728 (3.344)	 Data 0.000 (2.658)	 Loss 11.671 (10.779)	 EPE 0.515 (0.708)
Epoch: [0][440/1000]	 Time 0.726 (3.332)	 Data 0.005 (2.646)	 Loss 10.408 (10.761)	 EPE 0.529 (0.705)
Epoch: [0][450/1000]	 Time 21.544 (3.366)	 Data 20.733 (2.680)	 Loss 9.769 (10.731)	 EPE 0.507 (0.702)
Epoch: [0][460/1000]	 Time 0.685 (3.354)	 Data 0.000 (2.668)	 Loss 9.150 (10.725)	 EPE 0.525 (0.700)
Epoch: [0][470/1000]	 Time 0.767 (3.343)	 Data 0.015 (2.656)	 Loss 11.605 (10.706)	 EPE 0.608 (0.697)
Epoch: [0][480/1000]	 Time 0.665 (3.332)	 Data 0.010 (2.645)	 Loss 9.865 (10.685)	 EPE 0.515 (0.693)
Epoch: [0][490/1000]	 Time 22.184 (3.366)	 Data 21.402 (2.680)	 Loss 9.489 (10.671)	 EPE 0.449 (0.693)
Epoch: [0][500/1000]	 Time 0.747 (3.356)	 Data 0.020 (2.670)	 Loss 9.460 (10.653)	 EPE 0.431 (0.690)
Epoch: [0][510/1000]	 Time 0.643 (3.346)	 Data 0.000 (2.660)	 Loss 9.890 (10.650)	 EPE 0.545 (0.689)
Epoch: [0][520/1000]	 Time 0.688 (3.337)	 Data 0.015 (2.652)	 Loss 9.566 (10.635)	 EPE 0.654 (0.687)
Epoch: [0][530/1000]	 Time 21.957 (3.368)	 Data 21.297 (2.682)	 Loss 9.389 (10.621)	 EPE 0.555 (0.685)
Epoch: [0][540/1000]	 Time 0.724 (3.358)	 Data 0.020 (2.672)	 Loss 11.781 (10.605)	 EPE 0.726 (0.683)
Epoch: [0][550/1000]	 Time 0.679 (3.351)	 Data 0.000 (2.665)	 Loss 11.409 (10.585)	 EPE 1.093 (0.682)
Epoch: [0][560/1000]	 Time 0.673 (3.342)	 Data 0.000 (2.656)	 Loss 10.848 (10.576)	 EPE 0.758 (0.681)
Epoch: [0][570/1000]	 Time 21.966 (3.370)	 Data 21.201 (2.685)	 Loss 10.487 (10.567)	 EPE 0.463 (0.680)
Epoch: [0][580/1000]	 Time 0.716 (3.363)	 Data 0.000 (2.677)	 Loss 10.585 (10.561)	 EPE 0.346 (0.678)
Epoch: [0][590/1000]	 Time 0.670 (3.354)	 Data 0.005 (2.668)	 Loss 8.921 (10.552)	 EPE 0.370 (0.676)
Epoch: [0][600/1000]	 Time 0.744 (3.344)	 Data 0.000 (2.658)	 Loss 7.886 (10.536)	 EPE 0.377 (0.674)
Epoch: [0][610/1000]	 Time 21.284 (3.371)	 Data 20.659 (2.685)	 Loss 11.890 (10.529)	 EPE 0.631 (0.672)
Epoch: [0][620/1000]	 Time 0.677 (3.362)	 Data 0.000 (2.676)	 Loss 10.622 (10.510)	 EPE 0.437 (0.669)
Epoch: [0][630/1000]	 Time 0.770 (3.353)	 Data 0.000 (2.665)	 Loss 10.246 (10.515)	 EPE 0.566 (0.671)
Epoch: [0][640/1000]	 Time 0.768 (3.345)	 Data 0.020 (2.658)	 Loss 12.168 (10.514)	 EPE 0.970 (0.671)
Epoch: [0][650/1000]	 Time 22.301 (3.371)	 Data 21.592 (2.683)	 Loss 8.668 (10.504)	 EPE 0.381 (0.670)
Epoch: [0][660/1000]	 Time 0.697 (3.362)	 Data 0.010 (2.674)	 Loss 7.941 (10.494)	 EPE 0.336 (0.668)
Epoch: [0][670/1000]	 Time 0.673 (3.353)	 Data 0.000 (2.665)	 Loss 9.099 (10.487)	 EPE 0.627 (0.666)
Epoch: [0][680/1000]	 Time 0.749 (3.345)	 Data 0.000 (2.657)	 Loss 12.892 (10.490)	 EPE 1.081 (0.666)
Epoch: [0][690/1000]	 Time 21.658 (3.370)	 Data 21.029 (2.682)	 Loss 10.540 (10.493)	 EPE 0.671 (0.666)
Epoch: [0][700/1000]	 Time 0.693 (3.362)	 Data 0.010 (2.674)	 Loss 8.977 (10.470)	 EPE 0.467 (0.665)
Epoch: [0][710/1000]	 Time 0.727 (3.354)	 Data 0.005 (2.666)	 Loss 9.097 (10.451)	 EPE 0.572 (0.663)
Epoch: [0][720/1000]	 Time 0.670 (3.347)	 Data 0.005 (2.659)	 Loss 10.389 (10.443)	 EPE 0.614 (0.661)
Epoch: [0][730/1000]	 Time 21.605 (3.369)	 Data 20.858 (2.681)	 Loss 8.955 (10.428)	 EPE 0.375 (0.660)
Epoch: [0][740/1000]	 Time 0.704 (3.362)	 Data 0.000 (2.673)	 Loss 11.059 (10.418)	 EPE 0.854 (0.659)
Epoch: [0][750/1000]	 Time 0.676 (3.355)	 Data 0.000 (2.667)	 Loss 10.277 (10.410)	 EPE 0.619 (0.658)
Epoch: [0][760/1000]	 Time 0.721 (3.349)	 Data 0.000 (2.660)	 Loss 10.266 (10.401)	 EPE 0.651 (0.657)
Epoch: [0][770/1000]	 Time 21.150 (3.369)	 Data 20.454 (2.681)	 Loss 14.319 (10.400)	 EPE 0.647 (0.656)
Epoch: [0][780/1000]	 Time 0.750 (3.363)	 Data 0.000 (2.673)	 Loss 7.832 (10.385)	 EPE 0.399 (0.654)
Epoch: [0][790/1000]	 Time 0.689 (3.355)	 Data 0.000 (2.666)	 Loss 11.079 (10.388)	 EPE 0.773 (0.654)
Epoch: [0][800/1000]	 Time 0.627 (3.349)	 Data 0.000 (2.659)	 Loss 9.570 (10.378)	 EPE 0.535 (0.653)
Epoch: [0][810/1000]	 Time 21.530 (3.368)	 Data 20.799 (2.679)	 Loss 9.303 (10.371)	 EPE 0.480 (0.651)
Epoch: [0][820/1000]	 Time 0.731 (3.363)	 Data 0.000 (2.673)	 Loss 7.333 (10.349)	 EPE 0.288 (0.649)
Epoch: [0][830/1000]	 Time 0.795 (3.357)	 Data 0.005 (2.667)	 Loss 8.609 (10.340)	 EPE 0.559 (0.648)
Epoch: [0][840/1000]	 Time 0.704 (3.352)	 Data 0.000 (2.662)	 Loss 11.569 (10.338)	 EPE 0.829 (0.647)
Epoch: [0][850/1000]	 Time 22.006 (3.371)	 Data 21.303 (2.681)	 Loss 10.524 (10.340)	 EPE 0.508 (0.648)
Epoch: [0][860/1000]	 Time 0.600 (3.365)	 Data 0.005 (2.675)	 Loss 9.717 (10.337)	 EPE 0.414 (0.647)
Epoch: [0][870/1000]	 Time 0.714 (3.358)	 Data 0.000 (2.669)	 Loss 10.651 (10.331)	 EPE 0.589 (0.646)
Epoch: [0][880/1000]	 Time 0.725 (3.352)	 Data 0.000 (2.663)	 Loss 7.181 (10.322)	 EPE 0.535 (0.644)
Epoch: [0][890/1000]	 Time 22.075 (3.371)	 Data 21.334 (2.681)	 Loss 6.994 (10.316)	 EPE 0.490 (0.644)
Epoch: [0][900/1000]	 Time 0.699 (3.365)	 Data 0.000 (2.675)	 Loss 11.894 (10.335)	 EPE 0.929 (0.647)
Epoch: [0][910/1000]	 Time 0.688 (3.359)	 Data 0.005 (2.669)	 Loss 8.507 (10.329)	 EPE 0.447 (0.646)
Epoch: [0][920/1000]	 Time 0.741 (3.353)	 Data 0.000 (2.664)	 Loss 9.901 (10.311)	 EPE 0.603 (0.645)
Epoch: [0][930/1000]	 Time 21.137 (3.370)	 Data 20.428 (2.680)	 Loss 9.549 (10.314)	 EPE 0.456 (0.645)
Epoch: [0][940/1000]	 Time 0.785 (3.364)	 Data 0.010 (2.674)	 Loss 10.135 (10.306)	 EPE 0.519 (0.643)
Epoch: [0][950/1000]	 Time 0.704 (3.358)	 Data 0.000 (2.668)	 Loss 9.849 (10.296)	 EPE 0.470 (0.642)
Epoch: [0][960/1000]	 Time 0.708 (3.352)	 Data 0.005 (2.662)	 Loss 9.815 (10.294)	 EPE 0.641 (0.641)
Epoch: [0][970/1000]	 Time 22.184 (3.369)	 Data 21.398 (2.678)	 Loss 11.200 (10.305)	 EPE 0.534 (0.643)
Epoch: [0][980/1000]	 Time 0.688 (3.363)	 Data 0.005 (2.673)	 Loss 9.874 (10.302)	 EPE 0.456 (0.643)
Epoch: [0][990/1000]	 Time 0.673 (3.358)	 Data 0.000 (2.667)	 Loss 8.452 (10.297)	 EPE 0.494 (0.642)
Epoch: [0][1000/1000]	 Time 0.761 (3.353)	 Data 0.000 (2.662)	 Loss 9.143 (10.291)	 EPE 0.661 (0.641)
/cluster/apps/python/3.8.5_gpu_gcc630/x86_64/lib64/python3.8/site-packages/torch/nn/functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn("Default grid_sample and affine_grid behavior has changed "
User defined signal 2
